{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a25362e-7964-48e2-9b31-0caefd3eff98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Treinamento de Rede Neural com SNR aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00aefe53-addb-47d1-8359-9811b4f0e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 10:48:02.300179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 10:48:02.300205: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 10:48:02.330955: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-02 10:48:03.030998: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 10:48:03.031077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 10:48:03.031087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from libs.commpy_mod import SISOFlatChannel\n",
    "\n",
    "from files_01_detection.const_mod import generate_symbols, Model\n",
    "from files_01_detection.const_analyzer import plot_decision_boundary, theoretical_error, ser, plot_confusion_matrix, plot_symbols\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258bd235-88f3-42ab-a2f2-ceaaad3f990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_symbols  = 1000000    # Number of transmitted symbols to be used for training and test\n",
    "train_fraction = 0.5 # Fraction of whole data to be used for training (the remaining is for testing)\n",
    "code_rate    = 1       # Rate of the used code\n",
    "Es           = 1       # Average symbol energy\n",
    "Mod = 'PSK'\n",
    "channel_type = 'rayleigh' # 'awgn' or 'crazy'\n",
    "M            = 8      # PSK modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9170b1-16da-4aa7-9bac-556b46bb81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjunto(Mod, total_num_symbols, M, channel_type, Es, code_rate, SNR_dB, symb=False, scaler=None):\n",
    "\n",
    "    symbs, indices, channel_output = Model(Mod, total_num_symbols, M, channel_type, Es, code_rate, SNR_dB[0])\n",
    "    x = np.stack([np.real(channel_output[0][:]),\n",
    "                    np.imag(channel_output[0][:])], axis=1)\n",
    "\n",
    "    if scaler is not None:\n",
    "        x = scaler(np.concatenate((x, np.array([channel_output[1]]).T), axis=1))\n",
    "    else:\n",
    "        x = np.concatenate((x, np.array([channel_output[1]]).T), axis=1)\n",
    "    \n",
    "    x = x.reshape(1,-1,3)\n",
    "    \n",
    "    for i in range(1, len(SNR_dB)):\n",
    "        a, b, c = Model(Mod, total_num_symbols, M, channel_type, Es, code_rate, SNR_dB[i])\n",
    "        \n",
    "        d = np.stack([np.real(c[0][:]), np.imag(c[0][:])], axis=1)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            d = scaler(np.concatenate((d, np.array([c[1]]).T), axis=1))\n",
    "        else:\n",
    "            d = np.concatenate((d, np.array([c[1]]).T), axis=1)\n",
    "        \n",
    "        symbs = np.vstack((symbs, a))\n",
    "        indices = np.vstack((indices, b))\n",
    "        channel_output = np.vstack((channel_output, c))\n",
    "        x = np.vstack((x, d.reshape(1,-1,3)))\n",
    "    \n",
    "    y = np.float_(indices)\n",
    "        \n",
    "    if symb:\n",
    "        return x, y, symbs\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f1bcc1-5a31-4c95-8c66-e1281f6ac674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    indices = np.array([])\\n    symbs = np.array([])\\n    channel_output = np.array([])\\n    alpha = np.array([])\\n    for i in range(total_num_symbols):\\n        a, b, c = Model(Mod, 1, M, channel_type, Es, code_rate, np.random.randint(min, max))\\n        symbs = np.append(symbs, a)\\n        indices = np.append(indices, b)\\n        channel_output = np.append(channel_output, c[0])\\n        alpha = np.append(alpha, c[1])\\n        \\n    x = np.stack([np.real(channel_output[:]),\\n                        np.imag(channel_output[:])], axis=1)\\n    x = np.concatenate((x, np.array([alpha]).T), axis=1)\\n    \\n    y = np.float_(indices)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Train_Data(Mod, total_num_symbols, M, channel_type, Es, code_rate, min, max):\n",
    "\n",
    "    symbs, indices, channel_output = Model(Mod, total_num_symbols, M, channel_type, Es, code_rate, [min, max])\n",
    "    x = np.stack([np.real(channel_output[0][:]),\n",
    "                    np.imag(channel_output[0][:])], axis=1)\n",
    "    x = np.concatenate((x, np.array([np.real(channel_output[1])]).T), axis=1)\n",
    "    \n",
    "    y = np.float_(indices[0])\n",
    "    \n",
    "    return x, y, symbs\n",
    "\"\"\"\n",
    "    indices = np.array([])\n",
    "    symbs = np.array([])\n",
    "    channel_output = np.array([])\n",
    "    alpha = np.array([])\n",
    "    for i in range(total_num_symbols):\n",
    "        a, b, c = Model(Mod, 1, M, channel_type, Es, code_rate, np.random.randint(min, max))\n",
    "        symbs = np.append(symbs, a)\n",
    "        indices = np.append(indices, b)\n",
    "        channel_output = np.append(channel_output, c[0])\n",
    "        alpha = np.append(alpha, c[1])\n",
    "        \n",
    "    x = np.stack([np.real(channel_output[:]),\n",
    "                        np.imag(channel_output[:])], axis=1)\n",
    "    x = np.concatenate((x, np.array([alpha]).T), axis=1)\n",
    "    \n",
    "    y = np.float_(indices)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cfb288-c243-44e6-8f10-7f1a7c0f59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out, y_out, symbs = Train_Data(Mod, total_num_symbols, M, channel_type, Es, code_rate, 5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe59e1-aad4-47e6-a683-eef8657652bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out.tofile('x_rand.dat')\n",
    "y_out.tofile('y_rand.dat')\n",
    "symbs.tofile('symb.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94705521-39a7-4daa-ab0c-54eccfde1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = np.fromfile('x_rand.dat', dtype=np.dtype())\n",
    "y_out = np.fromfile('y_rand.dat', dtype=np.dtype())\n",
    "symbs = np.fromfile('symb.dat', dtype=np.dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f53ec6-7c5f-4c23-a474-29b560b2d739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 1., 2., 6., 6.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd8dcca-a54a-4a25-b52a-ce27be491dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 7. 0. 0. 7.]]\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(X_train)  \u001b[38;5;66;03m# Don't cheat - fit only on training data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m---> 16\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DL-22/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:975\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    972\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    974\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m--> 975\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/anaconda3/envs/DL-22/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/envs/DL-22/lib/python3.10/site-packages/sklearn/utils/validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    916\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Generate dataset\n",
    "# Train\n",
    "train_size = int(train_fraction*total_num_symbols) #data used for training\n",
    "y_train = y_out[:train_size]\n",
    "X_train = x_out[:train_size]\n",
    "\n",
    "# Test\n",
    "y_test = y_out[train_size:]\n",
    "X_test = x_out[train_size:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378aa92-2fe2-40a2-b313-54fe0f7b6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_symbols(X_train, y_train, M, symbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f3529-0bd8-409f-83ff-26a04b5cc3ef",
   "metadata": {},
   "source": [
    "## Criação e treinamento da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffbbd5-11e5-467e-8880-cb74a5c82025",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = np.shape(X_train)[1]\n",
    "n_hidden1 = 150\n",
    "n_hidden2 = 80\n",
    "n_hidden3 = 50\n",
    "\n",
    "n_outputs = M\n",
    "learning_rate = 0.01\n",
    "n_epochs = 10\n",
    "batch_size = 800\n",
    "\n",
    "y_train = tf.reshape(tf.convert_to_tensor(y_train), [-1, 1])\n",
    "y_test = tf.reshape(tf.convert_to_tensor(y_test), [-1, 1])\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "X_train = tf.convert_to_tensor(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1922c-3a68-4302-b739-0600d937d38a",
   "metadata": {},
   "source": [
    "### Usando API Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e802a8-800e-4d74-84fa-046b2914db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(3,))\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=\"elu\", kernel_initializer=\"glorot_normal\")(inputs)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=\"elu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden3, activation=\"elu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "\n",
    "output = tf.keras.layers.Dense(n_outputs, kernel_initializer=\"glorot_normal\")(x)\n",
    "#output = tf.keras.layers.BatchNormalization(momentum=0.99)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1b5fc-08ef-4313-b4d8-284e23e908e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_PSK.append(tf.keras.Model(inputs=inputs, outputs=output))\n",
    "\n",
    "model_PSK.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_PSK.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, shuffle=True)\n",
    "\n",
    "tests_score = model_PSK.evaluate(X_test, y_test)\n",
    "print(\"\\nTest loss:\", tests_score[0])\n",
    "print(\"Test accuracy:\", tests_score[1])\n",
    "print(f\"Taxa de erro simbólica de {(1 - tests_score[1]):.2%}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de663897-0659-49a2-af2d-963ce1fe1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(M, X_test, y_test, M, nn=True)\n",
    "#plot_decision_boundary(modelK, X_train, y_train, legend=True, nn=True)\n",
    "#plot_decision_boundary(modelK, X_train, y_train, legend=True, nn=True, plot_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a7647-fe9a-482e-953d-134bfdfbf498",
   "metadata": {},
   "source": [
    "## Avaliação do modelo em diferentes faixas de relação sinal/ruído"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a89ec-c423-461d-acdd-382c4c09142c",
   "metadata": {},
   "source": [
    "### PSK | Rayleigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ad085-2e60-4488-85d6-b43719026f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod = \"PSK\"\n",
    "channel_type = \"rayleigh\"\n",
    "M = 8\n",
    "init_scale = 2\n",
    "interval = 50\n",
    "passo = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010bf85-51f0-4e85-8078-aa8cdb546675",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teo_SNRs = [theoretical_error(Mod, M, init_scale + i, channel_type) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611eeaa-f773-488d-82a7-3234912b5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras = [conjunto(Mod, int(200 / (Teo_SNRs[int(i / passo)] * np.log2(M))), M, channel_type, Es, code_rate, [init_scale + i], False, scaler.transform) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b5efa-051b-49fb-b8dd-cca5b9e7db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = ([ser(model_PSK, tf.reshape(tf.convert_to_tensor(amostras[i][0]), [-1, 3]),\n",
    "                              tf.reshape(tf.convert_to_tensor(amostras[i][1]), [-1, 1]), nn=True)\n",
    "              for i in range(len(amostras))]) / (tf.math.log(float(M))/tf.math.log(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b35d6-3cc0-432b-a8ae-7d608915eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed90e5-a4bf-4a4c-9e73-c3f2675aed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(error_rate - Teo_SNRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48373b34-5fdf-4d34-8718-dcf8a76f3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as tick\n",
    "\n",
    "y1 = Teo_SNRs\n",
    "x = range(init_scale, init_scale + interval, passo)\n",
    "y2 = error_rate\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(x, y1, 'go-', label='Theoretical Curve', linewidth=2)\n",
    "ax.plot(x, y2, 'rs--', label='Empirical Curve')\n",
    "ax.set_title('8-PSK - Rayleigh')\n",
    "ax.set_xlabel('SNR_dB')\n",
    "ax.set_ylabel('Taxa de erro por bit')\n",
    "\n",
    "def y_fmt(x, y):\n",
    "    return '{:2.1e}'.format(x)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "#plt.plot(x2, y2, 'rs--',  label='line 2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239eac7-8db3-4d3f-827e-beb9d0cd2c33",
   "metadata": {},
   "source": [
    "### PSK | AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a1d7a-45df-4977-9328-b6dce0334cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod = 'PSK'\n",
    "channel_type = 'awgn'\n",
    "interval = 17\n",
    "init_scale = 2\n",
    "passo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eacb0c-aaff-4370-aca6-fb84622a7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teo_SNRs = [theoretical_error(Mod, M, init_scale + i, channel_type) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ada92-9ed0-4adc-b718-3e0b832c886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras = [conjunto(Mod, int(100 / (Teo_SNRs[int(i / passo)] * np.log2(M))), M, channel_type, Es, code_rate, init_scale + i, False, scaler.transform) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ae7c2-2646-4e26-83ea-1ed31261c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = ([ser(model_PSK, tf.reshape(tf.convert_to_tensor(amostras[i][0]), [-1, 3]),\n",
    "                              tf.reshape(tf.convert_to_tensor(amostras[i][1]), [-1, 1]), nn=True)\n",
    "              for i in range(len(amostras))]) / (tf.math.log(float(M))/tf.math.log(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b58b1-ab35-465c-b0cd-cc2acb631fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5fbe6-a38b-4e14-afba-a868bca6dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as tick\n",
    "\n",
    "y1 = Teo_SNRs\n",
    "x = range(init_scale, init_scale + interval, passo)\n",
    "y2 = error_rate\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(x, y1, 'go-', label='Theoretical Curve', linewidth=2)\n",
    "ax.plot(x, y2, 'rs--', label='Empirical Curve')\n",
    "ax.set_title('8-PSK - AWGN')\n",
    "ax.set_xlabel('SNR_dB')\n",
    "ax.set_ylabel('Taxa de erro por bit')\n",
    "\n",
    "def y_fmt(x, y):\n",
    "    return '{:2.1e}'.format(x)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "#plt.plot(x2, y2, 'rs--',  label='line 2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff1dad-7b5b-4797-b849-015db2038480",
   "metadata": {},
   "source": [
    "## Modelo QAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9e7a8-938f-4cfb-ab8f-d2a074995ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mod = \"QAM\"\n",
    "channel_type = \"rayleigh\"\n",
    "M = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01549568-82aa-474d-a34e-b5a04276eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out, y_out, symbs = Train_Data(Mod, total_num_symbols, M, channel_type, Es, code_rate, 5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcba47d-999e-48eb-a354-ed4cd878fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "# Train\n",
    "train_size = int(train_fraction*total_num_symbols) #data used for training\n",
    "y_train = y_out[:train_size]\n",
    "X_train = x_out[:train_size]\n",
    "\n",
    "# Test\n",
    "y_test = y_out[train_size:]\n",
    "X_test = x_out[train_size:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f761662-67cb-462c-87ae-8ad70e4598f5",
   "metadata": {},
   "source": [
    "## Criação e treinamento da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa156a7-8190-4be8-96ea-33165ff60c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = np.shape(X_train)[1]\n",
    "#n_hidden1 = 300\n",
    "n_hidden1 = 150\n",
    "n_hidden2 = 80\n",
    "n_hidden3 = 50\n",
    "\n",
    "n_outputs = M\n",
    "learning_rate = 0.001\n",
    "n_epochs = 10\n",
    "batch_size = 800\n",
    "\n",
    "y_train = tf.reshape(tf.convert_to_tensor(y_train), [-1, 1])\n",
    "y_test = tf.reshape(tf.convert_to_tensor(y_test), [-1, 1])\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "X_train = tf.convert_to_tensor(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af33df7-c16f-4184-a487-a3b469d87778",
   "metadata": {},
   "source": [
    "### Usando API Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4480f6-4c68-46a2-b080-147ec69673f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(3,))\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=\"elu\", kernel_initializer=\"glorot_normal\")(inputs)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=\"elu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden3, activation=\"elu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "#x = tf.keras.layers.Dense(n_hidden4, activation=\"elu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization(momentum=0.99)(x)\n",
    "#x = tf.keras.layers.Activation(\"elu\")(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(n_outputs, kernel_initializer=\"glorot_normal\")(x)\n",
    "#output = tf.keras.layers.BatchNormalization(momentum=0.99)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c7e22-1b26-46fb-9e7a-eb0774376efc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_QAM = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model_QAM.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_QAM.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, shuffle=True)\n",
    "\n",
    "tests_score = model_QAM.evaluate(X_test, y_test)\n",
    "print(\"\\nTest loss:\", tests_score[0])\n",
    "print(\"Test accuracy:\", tests_score[1])\n",
    "print(f\"Taxa de erro simbólica de {(1 - tests_score[1]):.2%}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22953f-27eb-4150-bcc2-36ea56258e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(M, X_test, y_test, M, nn=True)\n",
    "#plot_decision_boundary(modelQ, X_train, y_train, legend=True, nn=True)\n",
    "#plot_decision_boundary(modelQ, X_train, y_train, legend=True, nn=True, plot_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97cbd8-17d7-4670-b6f8-ece2c8a36004",
   "metadata": {},
   "source": [
    "## Avaliação do modelo em diferentes faixas de relação sinal/ruído"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ada27-3b9e-462c-b9c3-7ddc77b1a479",
   "metadata": {},
   "source": [
    "### QAM | Rayleigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44146543-1b92-48db-923a-73ff1539d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod = 'QAM'\n",
    "channel_type = 'rayleigh'\n",
    "M = 16\n",
    "init_scale = 2\n",
    "interval = 48\n",
    "passo = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d226b67-12ad-4937-87a3-fa299afaa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teo_SNRs = [theoretical_error(Mod, M, init_scale + i, channel_type) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd5440-36e5-4e14-82ba-be1178876b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras = [conjunto(Mod, int(200 / (Teo_SNRs[int(i / passo)] * np.log2(M))), M, channel_type, Es, code_rate, init_scale + i, False, scaler.transform) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92b6ef-9b1f-4db1-b34d-f9d6409fbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = ([ser(model_QAM, tf.reshape(tf.convert_to_tensor(amostras[i][0]), [-1, 3]),\n",
    "                              tf.reshape(tf.convert_to_tensor(amostras[i][1]), [-1, 1]), nn=True)\n",
    "              for i in range(len(amostras))]) / (tf.math.log(float(M))/tf.math.log(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0257d3-9c8b-458e-ac4e-f503d0f1f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f74f2-aced-44f4-8eba-9489967882a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(error_rate - Teo_SNRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f198833-3936-4af8-a5a4-6fc496d46327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as tick\n",
    "\n",
    "y1 = Teo_SNRs\n",
    "x = range(init_scale, init_scale + interval, passo)\n",
    "y2 = error_rate\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(x, y1, 'go-', label='Theoretical Curve', linewidth=2)\n",
    "ax.plot(x, y2, 'rs--', label='Empirical Curve')\n",
    "ax.set_title('16-QAM - Rayleigh')\n",
    "ax.set_xlabel('SNR_dB')\n",
    "ax.set_ylabel('Taxa de erro por bit')\n",
    "\n",
    "def y_fmt(x, y):\n",
    "    return '{:2.1e}'.format(x)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "#plt.plot(x2, y2, 'rs--',  label='line 2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da82bb-a17d-4e48-907b-956dfe0f00d7",
   "metadata": {},
   "source": [
    "### QAM | AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdfd547-1599-49c9-94a0-95eeaaec1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod = 'QAM'\n",
    "channel_type = 'awgn'\n",
    "init_scale = 2\n",
    "interval = 19\n",
    "passo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5411b10-2e61-42ab-ae38-56fc6a688dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teo_SNRs = [theoretical_error(Mod, M, init_scale + i, channel_type) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb35f2-9452-4409-a7b4-2968a16f8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras = [conjunto(Mod, int(100 / (Teo_SNRs[int(i / passo)] * np.log2(M))), M, channel_type, Es, code_rate, init_scale + i, False, scaler.transform) for i in range(0, interval, passo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd2673-736f-4cd9-b287-efe32d5fd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = ([ser(model_QAM, tf.reshape(tf.convert_to_tensor(amostras[i][0]), [-1, 3]),\n",
    "                              tf.reshape(tf.convert_to_tensor(amostras[i][1]), [-1, 1]), nn=True)\n",
    "              for i in range(len(amostras))]) / (tf.math.log(float(M))/tf.math.log(2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35470696-fd39-4b69-bf36-fddf694b223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b50d9-afed-4a53-9acc-5c4c32660d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as tick\n",
    "\n",
    "y1 = Teo_SNRs\n",
    "x = range(init_scale, init_scale + interval, passo)\n",
    "y2 = error_rate\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(x, y1, 'go-', label='Theoretical Curve', linewidth=2)\n",
    "ax.plot(x, y2, 'rs--', label='Empirical Curve')\n",
    "ax.set_title('16-QAM - AWGN')\n",
    "ax.set_xlabel('SNR_dB')\n",
    "ax.set_ylabel('Taxa de erro por bit')\n",
    "\n",
    "def y_fmt(x, y):\n",
    "    return '{:2.1e}'.format(x)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "#plt.plot(x2, y2, 'rs--',  label='line 2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
