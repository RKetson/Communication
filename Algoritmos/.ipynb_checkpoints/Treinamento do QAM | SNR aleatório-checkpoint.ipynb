{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb93000-d566-4d6d-aaf5-2ca9aa339fd0",
   "metadata": {},
   "source": [
    "# Treinamento QAM AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530446b9-6463-4cf0-94a3-534923e212f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:33:24.393469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-25 16:33:24.393495: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-25 16:33:24.421933: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-25 16:33:25.126764: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-25 16:33:25.126846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-25 16:33:25.126856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from libs.commpy_mod import SISOFlatChannel\n",
    "\n",
    "from files_01_detection.const_mod import generate_symbols, Model\n",
    "from files_01_detection.const_analyzer import plot_decision_boundary, theoretical_error, ser, plot_confusion_matrix, plot_symbols\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50290df4-2c5c-4c6f-8640-730198865a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_symbols  = 1000000    # Number of transmitted symbols to be used for training and test\n",
    "train_fraction = 0.4 # Fraction of whole data to be used for training (the remaining is for testing)\n",
    "code_rate    = 1       # Rate of the used code\n",
    "Es           = 1       # Average symbol energy\n",
    "Mod = 'QAM'\n",
    "channel_type = 'awgn' # 'awgn' or 'crazy'\n",
    "M            = [16, 4]      # PSK modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d08a3d-b359-4334-975e-3fd040b666b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(amostras, model, mod, M, channel_type, Es, code_rate, snr):\n",
    "    frac = 10000\n",
    "    error = 0\n",
    "    a = amostras\n",
    "    for i in range(amostras // frac + 1):\n",
    "        if a < frac:\n",
    "            frac = amostras % frac\n",
    "        sub_amostras =  conjunto(Mod, frac, M, channel_type, Es, code_rate, snr, False, scaler.transform)\n",
    "        error += ser(model, tf.reshape(tf.convert_to_tensor(sub_amostras[0]), [-1, 3]),\n",
    "                          tf.reshape(tf.convert_to_tensor(sub_amostras[1]), [-1, 1]), nn=True)\n",
    "        a -= frac\n",
    "    error /= amostras / frac\n",
    "    return error\n",
    "\n",
    "def conjunto(Mod, total_num_symbols, M, channel_type, Es, code_rate, SNR_dB, symb=False, scaler=None):\n",
    "\n",
    "    symbs, indices, channel_output = Model(Mod, total_num_symbols, M, channel_type, Es, code_rate, [SNR_dB[0]])\n",
    "    x = np.stack([np.real(channel_output[0][:]),\n",
    "                    np.imag(channel_output[0][:])], axis=1)\n",
    "\n",
    "    if scaler is not None:\n",
    "        x = scaler(np.concatenate((x, np.array([channel_output[1]]).T), axis=1))\n",
    "    else:\n",
    "        x = np.concatenate((x, np.array([channel_output[1]]).T), axis=1)\n",
    "    \n",
    "    x = x.reshape(1,-1,3)\n",
    "    \n",
    "    for i in range(1, len(SNR_dB)):\n",
    "        a, b, c = Model(Mod, total_num_symbols, M, channel_type, Es, code_rate, SNR_dB[i])\n",
    "        \n",
    "        d = np.stack([np.real(c[0][:]), np.imag(c[0][:])], axis=1)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            d = scaler(np.concatenate((d, np.array([c[1]]).T), axis=1))\n",
    "        else:\n",
    "            d = np.concatenate((d, np.array([c[1]]).T), axis=1)\n",
    "        \n",
    "        symbs = np.vstack((symbs, a))\n",
    "        indices = np.vstack((indices, b))\n",
    "        channel_output = np.vstack((channel_output, c))\n",
    "        x = np.vstack((x, d.reshape(1,-1,3)))\n",
    "    \n",
    "    y = np.float_(indices)\n",
    "        \n",
    "    if symb:\n",
    "        return x, y, symbs\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958252f4-80fc-4ec5-9adb-37f812dfc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = []\n",
    "y_out = []\n",
    "symbs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f46a11-bc56-4e4e-943d-4e70b7269ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out.append(np.fromfile('Random_Data/SNR_8-12/Rayleigh/16-QAM/x_rand.dat', dtype=np.dtype('float64')).reshape((-1,3)))\n",
    "y_out.append(np.fromfile('Random_Data/SNR_8-12/Rayleigh/16-QAM/y_rand.dat', dtype=np.dtype('float64')))\n",
    "symbs.append(np.fromfile('Random_Data/SNR_8-12/Rayleigh/16-QAM/symb.dat', dtype=np.dtype('complex128')).reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fba81a-5fb8-4d12-beee-4d0f3a183181",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out.append(np.fromfile('Random_Data/SNR_8-12/Rayleigh/4-QAM/x_rand.dat', dtype=np.dtype('float64')).reshape((-1,3)))\n",
    "y_out.append(np.fromfile('Random_Data/SNR_8-12/Rayleigh/4-QAM/y_rand.dat', dtype=np.dtype('float64')))\n",
    "symbs.append(np.fromfile('Random_Data/SNR_8-12/Rayleigh/4-QAM/symb.dat', dtype=np.dtype('complex128')).reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33caeed-5eab-4c41-80bd-0a84da19e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "# Train\n",
    "train_size = int(train_fraction*total_num_symbols) #data used for training\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(len(M)):\n",
    "    y_train.append(y_out[i][:train_size])\n",
    "    X_train.append(x_out[i][:train_size])\n",
    "\n",
    "    # Test\n",
    "    y_test.append(y_out[i][train_size:])\n",
    "    X_test.append(x_out[i][train_size:])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[i])  # Don't cheat - fit only on training data\n",
    "    X_train[i] = scaler.transform(X_train[i])\n",
    "    X_test[i] = scaler.transform(X_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9efd74-3088-4162-9201-a64a447765a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(M)):\n",
    "    plot_symbols(X_train[i], y_train[i], M[i], symbs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c90fdb-b167-4c7c-911a-a1e859b0c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555b77-df92-45bc-9477-7d5ccfad7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_redes = 3\n",
    "n_hidden = [[150, 80, 50],\n",
    "            [300, 180, 90, 40],\n",
    "            [500, 380, 240, 135, 80]]\n",
    "\n",
    "n_outputs = M\n",
    "learning_rate = [0.01, 0.01, 0.001]\n",
    "n_epochs = [50, 50, 50]\n",
    "batch_size = [8000, 16000, 24000]\n",
    "momentum = [0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b409e1-8736-4960-8c01-99c78be2ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tf = tf.reshape(tf.convert_to_tensor(y_train), [len(M), -1, 1])\n",
    "y_test_tf = tf.reshape(tf.convert_to_tensor(y_test), [len(M), -1, 1])\n",
    "X_test_tf = tf.convert_to_tensor(X_test)\n",
    "X_train_tf = tf.convert_to_tensor(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f808a5d-dbf8-4dd1-a7da-db1d8aacf198",
   "metadata": {},
   "source": [
    "### Usando API Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50a036-88b1-4f0c-8dfe-b4973fe54cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(n_inputs,))\n",
    "output = []\n",
    "\n",
    "for k in range(len(M)):\n",
    "    for i in range(n_redes):\n",
    "        x = inputs\n",
    "        for j in range(len(n_hidden[i])):\n",
    "            x = tf.keras.layers.Dense(n_hidden[i][j], activation=\"elu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "        output.append(tf.keras.layers.Dense(n_outputs[k], kernel_initializer=\"glorot_normal\")(x))\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab23fce-d70c-469f-877d-f3a3744a4742",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_QAM = []\n",
    "for k in range(len(M)):\n",
    "    for i in range(n_redes):\n",
    "        model_QAM.append(tf.keras.Model(inputs=inputs, outputs=output[i + 3*k]))\n",
    "\n",
    "        model_QAM[i + 3*k].compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                     optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=learning_rate[i], momentum=momentum[i], nesterov=True),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "        history = model_QAM[i + 3*k].fit(X_train_tf[k], y_train_tf[k], batch_size=batch_size[i], epochs=n_epochs[i], shuffle=True)\n",
    "\n",
    "        tests_score = model_QAM[i + 3*k].evaluate(X_test_tf[k], y_test_tf[k])\n",
    "        print(\"\\nTest loss:\", tests_score[0])\n",
    "        print(\"Test accuracy:\", tests_score[1])\n",
    "        print(f\"Taxa de erro simbólica de {(1 - tests_score[1]):.2%}\\n\")\n",
    "\n",
    "model_QAM = np.array(model_QAM).reshape(len(M), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ec243-e014-41ac-a0b2-f49b76ac0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(M)):\n",
    "    print(f'Modelo {M[i]}-QAM:\\n')\n",
    "    for j in range(n_redes):\n",
    "        plot_confusion_matrix(model_QAM[i][j], X_test_tf[i], y_test_tf[i], M[i], nn=True)\n",
    "#plot_decision_boundary(modelK, X_train, y_train, legend=True, nn=True)\n",
    "#plot_decision_boundary(modelK, X_train, y_train, legend=True, nn=True, plot_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d20538-9577-496e-b6e3-86568a104dd1",
   "metadata": {},
   "source": [
    "## Avaliação do modelo em diferentes faixas de relação sinal/ruído"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690772c-4548-431c-b8a7-44c508f88e0b",
   "metadata": {},
   "source": [
    "### QAM | AWGN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf628c6b-da05-4a12-82bc-c9d27ec23366",
   "metadata": {},
   "source": [
    "Obs: Subdividir amostras em conjuntos menores e realizar o treinamento (1000 subamostros por exemplo). Fazer a verificação de bits sem aproximação. Testar em um intervalo maior para verificar se a rede diverge em algum momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfdbd9d-8ab9-475e-a03c-08a937967249",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod = \"QAM\"\n",
    "channel_type = \"awgn\"\n",
    "init_scale = 1\n",
    "interval = [26, 15]\n",
    "passo = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba7463-dd2c-4cb6-9d88-f2eba60f4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teo_SNRs = [[theoretical_error(Mod, M[k], init_scale + i, channel_type) for i in range(0, interval[k], passo)] for k in range(len(M))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c31dd-8410-41e2-83ec-2a5cf8498393",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = [([[error(int(100 / (Teo_SNRs[k][int(i / passo)] * np.log2(M[k]))), model_QAM[k][j], Mod, M[k], channel_type, Es, code_rate, [init_scale + i]) for i in range(0, interval[k], passo)] for j in range(n_redes)]) / (tf.math.log(float(M[k]))/tf.math.log(2.)) for k in range(len(M))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1160bd-7fa0-4b7e-ab0a-a46ea03cb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4d5c7-0fad-4255-acab-cbbb7264aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(error_rate - Teo_SNRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec852a7a-d090-4ce2-a7c8-33d421208b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as tick\n",
    "\n",
    "for k in range(len(M)):\n",
    "    y1 = Teo_SNRs[k]\n",
    "    x = range(init_scale, init_scale + interval[k], passo)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "\n",
    "    ax.plot(x, y1, 'go-', label='Theoretical Curve', linewidth=2)\n",
    "    [ax.plot(x, error_rate[k][i], 's--', label=f'Empirical Curve (Rede {i + 1})') for i in range(n_redes)]\n",
    "\n",
    "    ax.set_title(f'{M[k]}-QAM - AWGN')\n",
    "    ax.set_xlabel('SNR_dB')\n",
    "    ax.set_ylabel('Taxa de erro por bit')\n",
    "\n",
    "    def y_fmt(x, y):\n",
    "        return '{:2.1e}'.format(x)\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "    #plt.plot(x2, y2, 'rs--',  label='line 2')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f38ef-abe3-4b62-80ca-c646b5695772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
