{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056b7760-0cf3-41a8-8f1e-2f9892653b5f",
   "metadata": {},
   "source": [
    "# Treinamento de Rede Neural com Tensorflow para análise do sinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98422160-e949-40ef-96ce-8be84199af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 10:50:35.781996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:50:35.782020: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-07 10:50:35.812053: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-07 10:50:36.517912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:50:36.517991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:50:36.518001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from libs.commpy_mod import SISOFlatChannel\n",
    "\n",
    "from files_01_detection.const_mod import generate_symbols, Model\n",
    "from files_01_detection.const_analyzer import plot_decision_boundary, theoretical_ser, ser, plot_confusion_matrix, plot_symbols\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca727e69-810e-4a7b-96ba-5d1f3b688cc8",
   "metadata": {},
   "source": [
    "## Definição e transmissão do sinal pelo canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa78a52-727e-4ed0-8fe6-89233d91e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mod = 'QAM'\n",
    "channel_type = 'rayleigh' # 'awgn' or 'crazy'\n",
    "M            = 16      # PSK modulation\n",
    "total_num_symbols  = 1000000    # Number of transmitted symbols to be used for training and test\n",
    "train_fraction = 0.5 # Fraction of whole data to be used for training (the remaining is for testing)\n",
    "SNR_dB       = 15      # Signal to noise ratio in dB     \n",
    "code_rate    = 1       # Rate of the used code\n",
    "Es           = 1       # Average symbol energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f0326f-e000-49df-a7fe-ac2eec58af7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theoretical_ser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#plot theoretical symbol error probability (SER) for this SNR\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Pe \u001b[38;5;241m=\u001b[39m \u001b[43mtheoretical_ser\u001b[49m(Mod, M, SNR_dB, channel_type, Es)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheoretical symbol error probability (SER) =\u001b[39m\u001b[38;5;124m\"\u001b[39m, Pe, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for SNR =\u001b[39m\u001b[38;5;124m\"\u001b[39m, SNR_dB,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'theoretical_ser' is not defined"
     ]
    }
   ],
   "source": [
    "#plot theoretical symbol error probability (SER) for this SNR\n",
    "Pe = theoretical_ser(Mod, M, SNR_dB, channel_type, Es)\n",
    "print(\"Theoretical symbol error probability (SER) =\", Pe, \" for SNR =\", SNR_dB,\"dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef8a7e-6d73-446a-936c-02dd692eedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbs, indices, channel_output = Model(Mod, total_num_symbols, M, channel_type, Es, code_rate, SNR_dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd15caf6-7df8-41e5-8ec5-6fd4cc06fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "# Train\n",
    "train_size = int(train_fraction*total_num_symbols) #data used for training\n",
    "y_train = np.append(np.array([[]]), indices[:train_size])\n",
    "X_train = np.stack([np.real(channel_output[:train_size]),\n",
    "                    np.imag(channel_output[:train_size])], axis=1)\n",
    "\n",
    "# Test\n",
    "y_test = np.append(np.array([[]]), indices[train_size:])\n",
    "X_test = np.stack([np.real(channel_output[train_size:]),\n",
    "                   np.imag(channel_output[train_size:])], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1586318c-e4a8-47a0-b11e-46fac0777c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_symbols(X_train, y_train, M, symbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c2744-0243-4fb7-8036-80539593fcad",
   "metadata": {},
   "source": [
    "## Criação e treinamento da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb58434-e47c-4f04-96b3-67696b236c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 10:02:09.251915: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252310: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252381: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-07 10:02:09.252463: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "n_inputs = np.shape(X_train)[1]\n",
    "n_hidden1 = 20\n",
    "n_hidden2 = 10\n",
    "n_outputs = M\n",
    "learning_rate = 0.001\n",
    "n_epochs = 100\n",
    "batch_size = 5000\n",
    "\n",
    "y_train = tf.reshape(tf.convert_to_tensor(y_train), [-1, 1])\n",
    "y_test = tf.reshape(tf.convert_to_tensor(y_test), [-1, 1])\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "X_train = tf.convert_to_tensor(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34138fb-0246-433f-ad3e-0637ebdb8eb5",
   "metadata": {},
   "source": [
    "### Usando API Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8615c883-116f-4af7-a4c7-ac3ec4a2bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 358\n",
      "Trainable params: 358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(2,))\n",
    "\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=\"relu\", kernel_initializer=\"glorot_normal\")(inputs)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=\"relu\", kernel_initializer=\"glorot_normal\")(x)\n",
    "output = tf.keras.layers.Dense(n_outputs, kernel_initializer=\"glorot_normal\")(x)\n",
    "\n",
    "modelK = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "modelK.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495612db-c4e4-43af-9e71-71ca99c1a083",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 3ms/step - loss: 2.0586 - accuracy: 0.1743\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0492 - accuracy: 0.2110\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0389 - accuracy: 0.2424\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0285 - accuracy: 0.2942\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0189 - accuracy: 0.3292\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0100 - accuracy: 0.3440\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0014 - accuracy: 0.3503\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9930 - accuracy: 0.3531\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9848 - accuracy: 0.3537\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9766 - accuracy: 0.3531\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9685 - accuracy: 0.3520\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9604 - accuracy: 0.3507\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9524 - accuracy: 0.3497\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9445 - accuracy: 0.3488\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9366 - accuracy: 0.3481\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9287 - accuracy: 0.3477\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9209 - accuracy: 0.3474\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9130 - accuracy: 0.3474\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9052 - accuracy: 0.3476\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8973 - accuracy: 0.3479\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8894 - accuracy: 0.3484\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8815 - accuracy: 0.3490\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8734 - accuracy: 0.3496\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8652 - accuracy: 0.3503\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8570 - accuracy: 0.3510\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8486 - accuracy: 0.3517\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8400 - accuracy: 0.3524\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8314 - accuracy: 0.3531\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8226 - accuracy: 0.3538\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8136 - accuracy: 0.3544\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8046 - accuracy: 0.3551\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7953 - accuracy: 0.3557\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7860 - accuracy: 0.3562\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7765 - accuracy: 0.3568\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7668 - accuracy: 0.3573\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7570 - accuracy: 0.3578\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7471 - accuracy: 0.3582\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7371 - accuracy: 0.3585\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7269 - accuracy: 0.3588\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7166 - accuracy: 0.3592\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7061 - accuracy: 0.3595\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6956 - accuracy: 0.3598\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6849 - accuracy: 0.3602\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6742 - accuracy: 0.3607\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6633 - accuracy: 0.3625\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6523 - accuracy: 0.3666\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6413 - accuracy: 0.3743\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6301 - accuracy: 0.3841\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6189 - accuracy: 0.3946\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6075 - accuracy: 0.4093\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5961 - accuracy: 0.4319\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5846 - accuracy: 0.4715\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5730 - accuracy: 0.5075\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5614 - accuracy: 0.5249\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5497 - accuracy: 0.5402\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5379 - accuracy: 0.5539\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5261 - accuracy: 0.5670\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5142 - accuracy: 0.5791\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5023 - accuracy: 0.5908\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4903 - accuracy: 0.6014\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4783 - accuracy: 0.6107\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4662 - accuracy: 0.6186\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4541 - accuracy: 0.6254\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4419 - accuracy: 0.6313\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4297 - accuracy: 0.6372\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4174 - accuracy: 0.6429\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.4051 - accuracy: 0.6485\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3928 - accuracy: 0.6538\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3804 - accuracy: 0.6590\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3679 - accuracy: 0.6636\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3554 - accuracy: 0.6682\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3429 - accuracy: 0.6726\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3302 - accuracy: 0.6772\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3176 - accuracy: 0.6817\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.3048 - accuracy: 0.6858\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2921 - accuracy: 0.6899\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2792 - accuracy: 0.6938\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2663 - accuracy: 0.6977\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2534 - accuracy: 0.7014\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2404 - accuracy: 0.7052\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2273 - accuracy: 0.7089\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2142 - accuracy: 0.7123\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2010 - accuracy: 0.7165\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1878 - accuracy: 0.7206\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1745 - accuracy: 0.7244\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1612 - accuracy: 0.7285\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1479 - accuracy: 0.7325\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1345 - accuracy: 0.7366\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1211 - accuracy: 0.7410\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1078 - accuracy: 0.7457\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0944 - accuracy: 0.7504\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.7556\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0676 - accuracy: 0.7630\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0543 - accuracy: 0.7742\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0410 - accuracy: 0.7904\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0278 - accuracy: 0.8104\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0146 - accuracy: 0.8314\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.8467\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.8565\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9756 - accuracy: 0.8623\n",
      "15625/15625 [==============================] - 15s 921us/step - loss: 0.9680 - accuracy: 0.8660\n",
      "Test loss: 0.9679504632949829\n",
      "Test accuracy: 0.8660299777984619\n",
      "Taxa de erro simbólica de 13.40%\n"
     ]
    }
   ],
   "source": [
    "modelK.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = modelK.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, shuffle=True)\n",
    "\n",
    "tests_score = modelK.evaluate(X_test, y_test)\n",
    "print(\"Test loss:\", tests_score[0])\n",
    "print(\"Test accuracy:\", tests_score[1])\n",
    "print(f\"Taxa de erro simbólica de {(1 - tests_score[1]):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca739f-9548-4985-ae87-950776fc4fd1",
   "metadata": {},
   "source": [
    "### Modelo de Rede Neural Criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a09078-9177-41a5-a718-3c098be5d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.cast(tf.reshape(y_test, -1),tf.int32)\n",
    "y_train = tf.cast(tf.reshape(y_train, -1),tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4929a87-b383-4576-8d0a-f3237d5b6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(tf.Module):\n",
    "    def __init__(self, n_neurons, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.n_neurons = n_neurons\n",
    "        self.is_built = False\n",
    "        \n",
    "    def __call__(self, X, activation=None, name=None):\n",
    "        if not self.is_built:\n",
    "            self.w = tf.Variable(tf.random.truncated_normal((X.shape[-1], self.n_neurons), stddev=(2 / tf.sqrt(tf.cast(self.n_neurons + X.shape[-1], tf.float32)))), name=str(name)+\"W\")\n",
    "            self.b = tf.Variable(tf.zeros([self.n_neurons]), dtype=tf.float32, name=str(name)+\"b\")\n",
    "            self.is_built = True\n",
    "            \n",
    "        Z = tf.matmul(X, self.w) + self.b\n",
    "        if activation is None:\n",
    "            return Z\n",
    "        else:\n",
    "            return activation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97502121-7f18-4bd5-9b72-d6c80ca1ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencialModel(tf.Module):\n",
    "    def __init__(self, n_hidden=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.hidden1 = DenseLayer(n_hidden1)\n",
    "        self.hidden2 = DenseLayer(n_hidden2)\n",
    "        self.output = DenseLayer(n_outputs)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        x = self.hidden1(tf.cast(X, tf.float32), activation=tf.nn.relu, name=\"hidden1-\")\n",
    "        x = self.hidden2(x, activation=tf.nn.relu, name=\"hidden2-\")\n",
    "        \n",
    "        return self.output(x, name=\"output-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be91b39b-8709-4e13-9f7a-8fe3bf1dcdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SequencialModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c0e6d0-54dd-431d-b8af-49a189d08a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, logits):\n",
    "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc2516b-a77f-4608-80c5-0a9320bcb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, learning_rate):\n",
    "    with tf.GradientTape() as g:\n",
    "        current_loss = loss(y, tf.cast(model(x), tf.float32))\n",
    "        \n",
    "    dp = g.gradient(current_loss, model.trainable_variables)\n",
    "    \n",
    "    for i in range(len(model.trainable_variables)):\n",
    "        model.trainable_variables[i].assign_sub(learning_rate * dp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e83dae12-4b65-48c4-9c74-2f2f705ee11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minilote(model, x, y):\n",
    "    for _ in range(n_epochs):\n",
    "        for interation in range(x.shape[0] // batch_size):\n",
    "            X_batch, y_batch = x[interation*batch_size:(interation+1)*batch_size], y[interation*batch_size:(interation+1)*batch_size]\n",
    "            train(model, X_batch, y_batch, learning_rate)\n",
    "        print(f\"Época número {_}, precisão de {accuracy(model, x, y):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ce2eaef-fe65-4ac4-9ada-ccfc1c7a8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y):\n",
    "    correct = tf.nn.in_top_k(y, model(x), 1)\n",
    "    return tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "654fc1d5-3473-4575-80be-92981559efe5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época número 0, precisão de 21.37%\n",
      "Época número 1, precisão de 23.50%\n",
      "Época número 2, precisão de 24.05%\n",
      "Época número 3, precisão de 25.24%\n",
      "Época número 4, precisão de 26.34%\n",
      "Época número 5, precisão de 27.72%\n",
      "Época número 6, precisão de 29.57%\n",
      "Época número 7, precisão de 31.02%\n",
      "Época número 8, precisão de 31.49%\n",
      "Época número 9, precisão de 32.03%\n",
      "Época número 10, precisão de 32.63%\n",
      "Época número 11, precisão de 33.29%\n",
      "Época número 12, precisão de 33.96%\n",
      "Época número 13, precisão de 34.60%\n",
      "Época número 14, precisão de 35.28%\n",
      "Época número 15, precisão de 35.93%\n",
      "Época número 16, precisão de 36.53%\n",
      "Época número 17, precisão de 37.07%\n",
      "Época número 18, precisão de 37.54%\n",
      "Época número 19, precisão de 38.05%\n",
      "Época número 20, precisão de 38.66%\n",
      "Época número 21, precisão de 39.33%\n",
      "Época número 22, precisão de 40.02%\n",
      "Época número 23, precisão de 40.82%\n",
      "Época número 24, precisão de 41.80%\n",
      "Época número 25, precisão de 43.03%\n",
      "Época número 26, precisão de 44.40%\n",
      "Época número 27, precisão de 45.73%\n",
      "Época número 28, precisão de 46.98%\n",
      "Época número 29, precisão de 48.12%\n",
      "Época número 30, precisão de 49.30%\n",
      "Época número 31, precisão de 50.40%\n",
      "Época número 32, precisão de 51.20%\n",
      "Época número 33, precisão de 51.74%\n",
      "Época número 34, precisão de 52.25%\n",
      "Época número 35, precisão de 52.78%\n",
      "Época número 36, precisão de 53.35%\n",
      "Época número 37, precisão de 53.98%\n",
      "Época número 38, precisão de 54.64%\n",
      "Época número 39, precisão de 55.25%\n",
      "Época número 40, precisão de 55.82%\n",
      "Época número 41, precisão de 56.33%\n",
      "Época número 42, precisão de 56.77%\n",
      "Época número 43, precisão de 57.16%\n",
      "Época número 44, precisão de 57.49%\n",
      "Época número 45, precisão de 57.81%\n",
      "Época número 46, precisão de 58.13%\n",
      "Época número 47, precisão de 58.41%\n",
      "Época número 48, precisão de 58.93%\n",
      "Época número 49, precisão de 59.50%\n",
      "Época número 50, precisão de 60.12%\n",
      "Época número 51, precisão de 60.74%\n",
      "Época número 52, precisão de 61.38%\n",
      "Época número 53, precisão de 62.10%\n",
      "Época número 54, precisão de 62.84%\n",
      "Época número 55, precisão de 63.69%\n",
      "Época número 56, precisão de 64.60%\n",
      "Época número 57, precisão de 65.56%\n",
      "Época número 58, precisão de 66.60%\n",
      "Época número 59, precisão de 68.21%\n",
      "Época número 60, precisão de 69.82%\n",
      "Época número 61, precisão de 71.38%\n",
      "Época número 62, precisão de 72.90%\n",
      "Época número 63, precisão de 74.34%\n",
      "Época número 64, precisão de 75.74%\n",
      "Época número 65, precisão de 77.10%\n",
      "Época número 66, precisão de 78.41%\n",
      "Época número 67, precisão de 79.62%\n",
      "Época número 68, precisão de 80.73%\n",
      "Época número 69, precisão de 81.73%\n",
      "Época número 70, precisão de 82.65%\n",
      "Época número 71, precisão de 83.50%\n",
      "Época número 72, precisão de 84.25%\n",
      "Época número 73, precisão de 84.95%\n",
      "Época número 74, precisão de 85.56%\n",
      "Época número 75, precisão de 86.09%\n",
      "Época número 76, precisão de 86.57%\n",
      "Época número 77, precisão de 86.97%\n",
      "Época número 78, precisão de 87.32%\n",
      "Época número 79, precisão de 87.61%\n",
      "Época número 80, precisão de 87.87%\n",
      "Época número 81, precisão de 88.12%\n",
      "Época número 82, precisão de 88.31%\n",
      "Época número 83, precisão de 88.49%\n",
      "Época número 84, precisão de 88.64%\n",
      "Época número 85, precisão de 88.77%\n",
      "Época número 86, precisão de 88.89%\n",
      "Época número 87, precisão de 89.00%\n",
      "Época número 88, precisão de 89.10%\n",
      "Época número 89, precisão de 89.18%\n",
      "Época número 90, precisão de 89.26%\n",
      "Época número 91, precisão de 89.35%\n",
      "Época número 92, precisão de 89.43%\n",
      "Época número 93, precisão de 89.49%\n",
      "Época número 94, precisão de 89.55%\n",
      "Época número 95, precisão de 89.61%\n",
      "Época número 96, precisão de 89.65%\n",
      "Época número 97, precisão de 89.70%\n",
      "Época número 98, precisão de 89.74%\n",
      "Época número 99, precisão de 89.78%\n"
     ]
    }
   ],
   "source": [
    "minilote(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88e37a15-6d90-44fb-9c99-2d91bc0559c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de erro simbólica de 10.13%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taxa de erro simbólica de {(1 - accuracy(model, X_test, y_test)):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdaf953-79e4-448e-bce8-5b0ba34ffeec",
   "metadata": {},
   "source": [
    "### Rede Neural com uso de Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a980872-5875-4693-8772-bec207efc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02c4e16c-2ec8-4c22-89a7-df0e68a9dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd00a9e6-94ae-4c9d-8db1-341e9d15a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para a criação das camadas ocultas\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        \n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        \n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            tf.print(Z)\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edac2c09-86d4-4bba-8267-42532b51eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, \"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6886f8c-9954-49da-8adc-d8bcd7d95aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff079b09-7ba0-4861-b47a-ead20a1c8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b3e32e0-2365-4555-ae24-e06bc926f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275932af-7892-4a45-838a-0977772f73ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 10:04:44.697815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.1664 Val accuracy: 0.160506\n",
      "1 Train accuracy: 0.179 Val accuracy: 0.172908\n",
      "2 Train accuracy: 0.2506 Val accuracy: 0.248746\n",
      "3 Train accuracy: 0.2526 Val accuracy: 0.251024\n",
      "4 Train accuracy: 0.2596 Val accuracy: 0.256622\n",
      "5 Train accuracy: 0.2708 Val accuracy: 0.269442\n",
      "6 Train accuracy: 0.2918 Val accuracy: 0.29134\n",
      "7 Train accuracy: 0.321 Val accuracy: 0.321796\n",
      "8 Train accuracy: 0.357 Val accuracy: 0.35311\n",
      "9 Train accuracy: 0.3668 Val accuracy: 0.365086\n",
      "10 Train accuracy: 0.3698 Val accuracy: 0.367576\n",
      "11 Train accuracy: 0.3748 Val accuracy: 0.370694\n",
      "12 Train accuracy: 0.3796 Val accuracy: 0.375034\n",
      "13 Train accuracy: 0.3864 Val accuracy: 0.380402\n",
      "14 Train accuracy: 0.3928 Val accuracy: 0.38671\n",
      "15 Train accuracy: 0.4044 Val accuracy: 0.394814\n",
      "16 Train accuracy: 0.4148 Val accuracy: 0.4056\n",
      "17 Train accuracy: 0.4276 Val accuracy: 0.4182\n",
      "18 Train accuracy: 0.4412 Val accuracy: 0.431912\n",
      "19 Train accuracy: 0.4566 Val accuracy: 0.445692\n",
      "20 Train accuracy: 0.4712 Val accuracy: 0.458134\n",
      "21 Train accuracy: 0.4814 Val accuracy: 0.470942\n",
      "22 Train accuracy: 0.4954 Val accuracy: 0.486658\n",
      "23 Train accuracy: 0.512 Val accuracy: 0.50534\n",
      "24 Train accuracy: 0.534 Val accuracy: 0.526054\n",
      "25 Train accuracy: 0.555 Val accuracy: 0.547206\n",
      "26 Train accuracy: 0.5712 Val accuracy: 0.566128\n",
      "27 Train accuracy: 0.5858 Val accuracy: 0.58184\n",
      "28 Train accuracy: 0.6008 Val accuracy: 0.595156\n",
      "29 Train accuracy: 0.6162 Val accuracy: 0.607498\n",
      "30 Train accuracy: 0.626 Val accuracy: 0.618938\n",
      "31 Train accuracy: 0.6352 Val accuracy: 0.629248\n",
      "32 Train accuracy: 0.643 Val accuracy: 0.638408\n",
      "33 Train accuracy: 0.6506 Val accuracy: 0.647076\n",
      "34 Train accuracy: 0.6586 Val accuracy: 0.654876\n",
      "35 Train accuracy: 0.6672 Val accuracy: 0.661436\n",
      "36 Train accuracy: 0.6726 Val accuracy: 0.666902\n",
      "37 Train accuracy: 0.678 Val accuracy: 0.671832\n",
      "38 Train accuracy: 0.6812 Val accuracy: 0.676132\n",
      "39 Train accuracy: 0.6852 Val accuracy: 0.679792\n",
      "40 Train accuracy: 0.687 Val accuracy: 0.683186\n",
      "41 Train accuracy: 0.6912 Val accuracy: 0.68659\n",
      "42 Train accuracy: 0.6938 Val accuracy: 0.690328\n",
      "43 Train accuracy: 0.6986 Val accuracy: 0.69452\n",
      "44 Train accuracy: 0.7034 Val accuracy: 0.70047\n",
      "45 Train accuracy: 0.7176 Val accuracy: 0.713916\n",
      "46 Train accuracy: 0.7426 Val accuracy: 0.740412\n",
      "47 Train accuracy: 0.77 Val accuracy: 0.769504\n",
      "48 Train accuracy: 0.8002 Val accuracy: 0.795772\n",
      "49 Train accuracy: 0.8208 Val accuracy: 0.817338\n",
      "50 Train accuracy: 0.8362 Val accuracy: 0.834408\n",
      "51 Train accuracy: 0.8512 Val accuracy: 0.848822\n",
      "52 Train accuracy: 0.8608 Val accuracy: 0.860908\n",
      "53 Train accuracy: 0.8712 Val accuracy: 0.87064\n",
      "54 Train accuracy: 0.8816 Val accuracy: 0.878442\n",
      "55 Train accuracy: 0.8856 Val accuracy: 0.88471\n",
      "56 Train accuracy: 0.8892 Val accuracy: 0.889404\n",
      "57 Train accuracy: 0.8914 Val accuracy: 0.893208\n",
      "58 Train accuracy: 0.8958 Val accuracy: 0.896046\n",
      "59 Train accuracy: 0.8972 Val accuracy: 0.898226\n",
      "60 Train accuracy: 0.8998 Val accuracy: 0.899946\n",
      "61 Train accuracy: 0.9014 Val accuracy: 0.901348\n",
      "62 Train accuracy: 0.9032 Val accuracy: 0.90236\n",
      "63 Train accuracy: 0.9028 Val accuracy: 0.903066\n",
      "64 Train accuracy: 0.9036 Val accuracy: 0.903524\n",
      "65 Train accuracy: 0.9046 Val accuracy: 0.90394\n",
      "66 Train accuracy: 0.9044 Val accuracy: 0.904262\n",
      "67 Train accuracy: 0.904 Val accuracy: 0.904444\n",
      "68 Train accuracy: 0.9038 Val accuracy: 0.904616\n",
      "69 Train accuracy: 0.9042 Val accuracy: 0.90475\n",
      "70 Train accuracy: 0.9044 Val accuracy: 0.904756\n",
      "71 Train accuracy: 0.9042 Val accuracy: 0.904826\n",
      "72 Train accuracy: 0.904 Val accuracy: 0.904904\n",
      "73 Train accuracy: 0.9036 Val accuracy: 0.905012\n",
      "74 Train accuracy: 0.9036 Val accuracy: 0.905034\n",
      "75 Train accuracy: 0.9042 Val accuracy: 0.905054\n",
      "76 Train accuracy: 0.9044 Val accuracy: 0.9051\n",
      "77 Train accuracy: 0.9046 Val accuracy: 0.905132\n",
      "78 Train accuracy: 0.9046 Val accuracy: 0.905212\n",
      "79 Train accuracy: 0.9046 Val accuracy: 0.905278\n",
      "80 Train accuracy: 0.9048 Val accuracy: 0.905284\n",
      "81 Train accuracy: 0.9046 Val accuracy: 0.905338\n",
      "82 Train accuracy: 0.905 Val accuracy: 0.905352\n",
      "83 Train accuracy: 0.9048 Val accuracy: 0.905412\n",
      "84 Train accuracy: 0.9048 Val accuracy: 0.905452\n",
      "85 Train accuracy: 0.9048 Val accuracy: 0.905506\n",
      "86 Train accuracy: 0.9048 Val accuracy: 0.905562\n",
      "87 Train accuracy: 0.905 Val accuracy: 0.905634\n",
      "88 Train accuracy: 0.905 Val accuracy: 0.905654\n",
      "89 Train accuracy: 0.9048 Val accuracy: 0.90574\n",
      "90 Train accuracy: 0.9048 Val accuracy: 0.905776\n",
      "91 Train accuracy: 0.9044 Val accuracy: 0.90581\n",
      "92 Train accuracy: 0.9046 Val accuracy: 0.90585\n",
      "93 Train accuracy: 0.9048 Val accuracy: 0.905872\n",
      "94 Train accuracy: 0.9046 Val accuracy: 0.905908\n",
      "95 Train accuracy: 0.9042 Val accuracy: 0.905928\n",
      "96 Train accuracy: 0.904 Val accuracy: 0.905966\n",
      "97 Train accuracy: 0.904 Val accuracy: 0.905956\n",
      "98 Train accuracy: 0.9044 Val accuracy: 0.905974\n",
      "99 Train accuracy: 0.9044 Val accuracy: 0.906014\n",
      "0.906014\n",
      "A taxa de erro simbólica obtida foi de 9.40%\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for interation in range(np.shape(X_train)[0] // batch_size):\n",
    "            X_batch = X_train[(interation*batch_size):(batch_size*(interation+1))]\n",
    "            y_batch = y_train[(interation*batch_size):(batch_size*(interation+1))]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "    acc_val = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(acc_val)\n",
    "    print(f'A taxa de erro simbólica obtida foi de {(1 - acc_val):.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
